{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb1ef01c",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2685ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q stable-audio-tools torch torchaudio einops numpy\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, Any\n",
    "import time\n",
    "from einops import rearrange\n",
    "from stable_audio_tools import get_pretrained_model\n",
    "from stable_audio_tools.inference.generation import generate_diffusion_cond\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6756c85a",
   "metadata": {},
   "source": [
    "## 2. Set Up GPU and Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64433b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.set_per_process_memory_fraction(0.9)\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")\n",
    "\n",
    "output_dir = Path(\"/kaggle/working/generated_audio\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9df7bd",
   "metadata": {},
   "source": [
    "## 3. Initialize the Stable Audio Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df71e341",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Stable Audio model... (this may take a moment)\")\n",
    "start_time = time.time()\n",
    "\n",
    "model, model_config = get_pretrained_model(\"stabilityai/stable-audio-open-1.0\")\n",
    "model = model.to(device)\n",
    "\n",
    "sample_rate = model_config[\"sample_rate\"]\n",
    "sample_size = model_config[\"sample_size\"]\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"✓ Model loaded in {elapsed:.1f}s\")\n",
    "print(f\"  Sample rate: {sample_rate} Hz\")\n",
    "print(f\"  Sample size: {sample_size}\")\n",
    "print(f\"  Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cb7fcf",
   "metadata": {},
   "source": [
    "## 4. Generate Sound Effects with GPU Acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a5b92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_audio(\n",
    "    prompt: str,\n",
    "    duration: int = 30,\n",
    "    guidance_scale: float = 7.0,\n",
    "    seed: Optional[int] = None,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Generate audio using Stable Audio on GPU.\"\"\"\n",
    "    conditioning = [{\n",
    "        \"prompt\": prompt,\n",
    "        \"seconds_start\": 0,\n",
    "        \"seconds_total\": duration,\n",
    "    }]\n",
    "    \n",
    "    safe_seed = seed if seed is not None else 0\n",
    "    if safe_seed == -1 or safe_seed > 2**31 - 1:\n",
    "        safe_seed = 42\n",
    "    \n",
    "    output = generate_diffusion_cond(\n",
    "        model,\n",
    "        steps=100,\n",
    "        cfg_scale=guidance_scale,\n",
    "        conditioning=conditioning,\n",
    "        sample_size=sample_size,\n",
    "        sigma_min=0.3,\n",
    "        sigma_max=500,\n",
    "        sampler_type=\"dpmpp-3m-sde\",\n",
    "        device=device,\n",
    "        seed=safe_seed,\n",
    "    )\n",
    "    \n",
    "    output = rearrange(output, \"b d n -> d (b n)\")\n",
    "    output = output.to(torch.float32).cpu()\n",
    "    \n",
    "    max_val = torch.max(torch.abs(output)).item()\n",
    "    if max_val > 1e-6:\n",
    "        output = output / max_val\n",
    "    \n",
    "    output = torch.clamp(output, -1.0, 1.0)\n",
    "    return output\n",
    "\n",
    "\n",
    "# Test with your prompt\n",
    "prompt = \"distant artillery shelling multiple times\"\n",
    "print(f\"Generating: '{prompt}'\")\n",
    "print(f\"Duration: 30s | Guidance Scale: 7.0\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "start_time = time.time()\n",
    "audio = generate_audio(prompt, duration=30, guidance_scale=7.0)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"✓ Generated in {elapsed:.1f}s\")\n",
    "print(f\"  Shape: {audio.shape}\")\n",
    "print(f\"  Min: {audio.min():.6f} | Max: {audio.max():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90b912c",
   "metadata": {},
   "source": [
    "## 5. Save and Verify Generated Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a8ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_audio = audio.float()\n",
    "output_scaled = (output_audio.numpy() * 32767.0).astype(\"int16\")\n",
    "\n",
    "output_path = output_dir / \"artillery_shelling.wav\"\n",
    "if output_scaled.ndim == 1:\n",
    "    output_scaled = output_scaled.reshape(1, -1)\n",
    "torchaudio.save(str(output_path), torch.from_numpy(output_scaled), sample_rate)\n",
    "\n",
    "print(f\"✓ Saved to: {output_path}\")\n",
    "print(f\"  File size: {output_path.stat().st_size / 1024 / 1024:.1f}MB\")\n",
    "print(f\"  Duration: {output_scaled.shape[1] / sample_rate:.1f}s\")\n",
    "\n",
    "from IPython.display import Audio\n",
    "Audio(str(output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb5e0f9",
   "metadata": {},
   "source": [
    "## 6. Batch Process Multiple Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948fb95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    {\"text\": \"distant artillery shelling multiple times\", \"duration\": 30},\n",
    "    {\"text\": \"heavy rain thunderstorm with wind\", \"duration\": 30},\n",
    "    {\"text\": \"eerie dark ambient drone sound\", \"duration\": 30},\n",
    "]\n",
    "\n",
    "print(f\"Batch processing {len(prompts)} prompts...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = []\n",
    "for i, item in enumerate(prompts, 1):\n",
    "    prompt = item[\"text\"]\n",
    "    duration = item[\"duration\"]\n",
    "    \n",
    "    print(f\"\\n[{i}/{len(prompts)}] Generating: '{prompt}'\")\n",
    "    print(f\"  Duration: {duration}s\")\n",
    "    \n",
    "    try:\n",
    "        start = time.time()\n",
    "        audio = generate_audio(prompt, duration=duration, guidance_scale=7.0)\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        output_audio = audio.float()\n",
    "        output_scaled = (output_audio.numpy() * 32767.0).astype(\"int16\")\n",
    "        \n",
    "        safe_filename = prompt.replace(\" \", \"_\")[:40] + \".wav\"\n",
    "        output_path = output_dir / safe_filename\n",
    "        \n",
    "        if output_scaled.ndim == 1:\n",
    "            output_scaled = output_scaled.reshape(1, -1)\n",
    "        torchaudio.save(str(output_path), torch.from_numpy(output_scaled), sample_rate)\n",
    "        \n",
    "        print(f\"  ✓ Generated in {elapsed:.1f}s\")\n",
    "        print(f\"  ✓ Saved to: {output_path.name}\")\n",
    "        \n",
    "        results.append({\"prompt\": prompt, \"file\": output_path.name, \"time\": elapsed})\n",
    "        \n",
    "        if device == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Batch complete! Generated {len(results)} audio files\")\n",
    "if results:\n",
    "    print(f\"Total time: {sum(r['time'] for r in results):.1f}s\")\n",
    "    print(f\"Average: {sum(r['time'] for r in results) / len(results):.1f}s per prompt\")\n",
    "print(f\"\\nOutput directory: {output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
